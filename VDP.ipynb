{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Powered Legal Research System\n",
    "## Hackathon Project: Legal RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "This notebook implements a legal research engine using:\n",
    "- **PDF Processing**: Extracts text from legal documents\n",
    "- **Vector Embeddings**: Creates semantic search capabilities\n",
    "- **FAISS**: Fast similarity search for retrieving relevant legal passages\n",
    "- **RAG Pipeline**: Generates accurate answers from legal documents\n",
    "\n",
    "---\n",
    "### Setup Instructions\n",
    "1. Run the installation cell below\n",
    "2. Run the main RAG system cell\n",
    "3. Test with legal queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gqXl1-2FOK2f",
    "outputId": "a43dbbc1-e917-487b-9416-780e6bafe6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "All packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install Required Packages\n",
    "# Run this cell ONCE at the beginning\n",
    "\n",
    "%pip install -q sentence-transformers faiss-cpu transformers PyPDF2 torch\n",
    "\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "72c4498a9caf45bf9867a38734cf7700",
      "fa63b2ddecda491f82efe8353836bc43",
      "d2b828ed38f2479ca46809c8e68aa6df",
      "44f0a9825dc44093a78b8808cf4ba3da",
      "d3f9ce74001e413787de8399effee228",
      "32981a0e1b6d4df683e78f6599220c78",
      "fe6432b518134df5bf6ffcca3a4d75c6",
      "3f65f124a5ce403a9b403447263a6b58",
      "f3f842b783b74c9cb8680f1fc232d500",
      "5d07484fda0e495e8c6bd984be78acdb",
      "161c5a285eaf44a58b36c00c3d734091",
      "fc9d7f2438904b6c9afc6a63d2a6c732",
      "bc9025d3e995445195890767f8135260",
      "e012cd0862754a60b50443e86cd89653",
      "26692f65ec06459db1fce35a2a8e1e9d",
      "3a94fda4f1be478e91e469ba0928d8f0",
      "63d3ead10592465ca881c315e68bc323",
      "cf946e1eae7c4c23b757c97c15457a77",
      "380ac78cbf2e472fa1746708e82c40fe",
      "72cd996c32af4ee0a43b18b6ed3a4556",
      "a576df8b703249ecb696090f30d72cc0",
      "4f128dd65b4e4f4ead00f49f9e31bfa2",
      "a41c72b9df54430194c174504a10a1a3",
      "3a2cd687f3e1486ea71de750ddf295c2",
      "9655cd4a1b344d9ba3ac2e2a2c232593",
      "bdd63046fc5c421a8098573f02401503",
      "eb7cd30f936d4c40b10313c72abff9b8",
      "2ea2dd83f28a4647a1a1eb3c6b7d8028",
      "5254457007b140eb92a7afd87f4d7afe",
      "662b9ea3a69b479c9e08d208cdd144f0",
      "c1315ed56d9542efaf58e17bccbf718e",
      "9d2f4cbd01d8495099b47041c2583c52",
      "9db208b6d95642a6af739fa2255211f4",
      "913626c960104f9f9a9719078ed9a36b",
      "973e4a0753eb4e3bb9fa1e90a3a90166",
      "4e301102f49e4201a3cd685ce0d15884",
      "8a6b09d767a64345a2361e9ef960fc23",
      "ec9636a2620f4a5597a8afa1882c581a",
      "cc88a8dfd04f4580a7b67b66c9af4557",
      "b5b411d062754e48a5b9e0a0c74b06eb",
      "d6c9b7a5b66d4c2abc1f0cfa593b8ff2",
      "49523065a4fb48a58469039320709852",
      "2d2dcc5c366a478686038e30cdf3feda",
      "a942a8424b554f439cdbcb14f8a9a7f5",
      "3fbd241f6bf04864a270246368e02370",
      "4d3b96f2a78f478a896eefc012692b25",
      "42ea39faf914483193b0a45836855ea5",
      "2e28838b3ebd4c4fb7beb94d15bfc6ca",
      "9c3d4f7d23df4ec796cbe9ffe39a9e82",
      "18ac4c7d72274ad49c7c94df99ac5582",
      "614a58a6f7774e97aee474f51655326b",
      "6c60aefadb0b4553967784e0a30aaa5a",
      "4dc38f4b61e54de194de3caca63aa348",
      "7e225df8bc5d422d8ec29ca387cd69c9",
      "e3d1ad3479c44ed8a31628cc4c940cfd",
      "f1a5fb3eb6994e9c8d2ef7e40a539849",
      "ef5b3edab2324e4eb0432b7e3e4c9d13",
      "73a48a9aa8b24f5783a31ff03e66c6b7",
      "00c32c80cc424b679713997e26e41242",
      "14458f1e438a4ed6b66c171322cf44b4",
      "ad1de2bb000449eea12245cbe4daf8c9",
      "dc3f6c687b65472199ae4c4113c62c77",
      "78b5a6dea8584c8bba197e8985320272",
      "e2d6b0873262495a968c19187374a5eb",
      "2d3637a0da554c55bb2bfb2551d73027",
      "891e7c1f4acb4f97aadd024021a1c597",
      "249bbf2e9a0d47f4a17a1fbd976893da",
      "8645d120b7b44f49b2b5245fc5cd017e",
      "f2fef93baa6d4a39956e402eaa521ede",
      "63614753de0a4e21ae4d7be5cd43a634",
      "72b717814b6649f080701261c67d4456",
      "7114a529b594449abb1cd56e921b9283",
      "b250e98aed4e4806b90d164a5eb6612f",
      "8eaa72cd965c4c35bb2705978bdc4f4d",
      "f1fdc1998e9c4aa8b5b09f637fd500ba",
      "a9b7b8f5064a40659eac51c4df948393",
      "6709db99b45948e3aef8f906fcf77e8b",
      "bcf3f721cf8840fdac3b1a1c02b70e4f",
      "0669bce1a1074211859dd1b13f433af6",
      "178626689865478e889af606f6df304e",
      "94fcea6ccfb94caaacada0f995f85a5f",
      "f16c9b24895542719169f318035395e8",
      "07e26fa989f64c04975c5d050a81fd38",
      "eb6019d57e0241dabf5dcee8de0bc7c8",
      "81d1ab024c0e47ccbc683a61cde05f45",
      "cb0b1f0d6479415f841de01157ed9e3b",
      "a157ce4ac08548b8a3e8cc75af5519c4",
      "cd9816f396d54095b3137e6d99748eef",
      "7916e31d0ba447da980d34f4f5f1349b",
      "8c9487f2278648d68d034190c985832b",
      "3dd778094dc34b9091601dc1023312b2",
      "9eb752d1854e46419079976028470d73",
      "ad6c7b9163f8482f834914df9b6bb00b",
      "d9f07c44b8b5475e8cdf0cf9a78f19cc",
      "0613748e638146a7b92d6cff4d8c2bfe",
      "40334f27c4494977995ae1f63e3aa879",
      "bebd6dd60e0a4c4bb973874ba36b0f39",
      "78faf1044306441e994817166557da2a",
      "17f58e7d65254af184a1b97cd77f44ee",
      "e944614825ae4f4b8f3399f83fbab0ce",
      "4d85a3c245354c44a9dccc4ae88c3bea",
      "732e2009cc614ec599747779843b8593",
      "08fecc03fad34436a0966de510fb79bd",
      "803e28248b27447fa2cf2a921708b295",
      "cc3367a6019246d4a2c5f0f33b876c18",
      "1282096b69544eadbf84bb3241fd0b93",
      "4b7d216ff63b4be5b33492bd95584d69",
      "a2f57b74feb24f6881a30709e4271b45",
      "a4a5d0bc1f8e405493e760f05e2a587a",
      "4888ec88f8a9487aabad2e5c81c95b0d",
      "7eb2477792164c2a8909c791d0f5cf96",
      "a30be450c9f54f3ca25e8842a48d1b5f",
      "cb94ead8dfe549c78419f92a649f51c8",
      "f29fc52168ae4abaa2e295658948f147",
      "1748c163ca4949b68b62e20b3dd52fc9",
      "8b1dbda21f39481cb60b4b3c1e32f966",
      "270c1ceaa89b4bf7bc2ad52f2ae25b5a",
      "22bc601a53444c5dae4cdef73396caf8",
      "f93f2938b5ce4b7fb484233205e8f893",
      "b096f64bbc6e46828c79ef1fc1e28f17",
      "a7bbd5dd17664052b4a8c1d95912337b",
      "28c8f2aa6bce4db5b4af2f7b4081af0d",
      "c4b415aa1590461a8611cc16903fbf19",
      "d0494a5282c343f0a3823d2ad287457c",
      "40febe8d2e11404481fde7ba8768040e",
      "a62ee6e11b8c4c6489f488111729a862",
      "20896fd5a8994a6a9c67bf20482906ce",
      "deba5034bea743978786b6a96ed20645",
      "b86090ea597640e89734eddd9e6820ab",
      "2ee3e60a1c584abf97e955baeff19e2b",
      "688cdc489d7e45148dea022ef13eb3b8",
      "75d1396578904cd5b0ae8052999dfaed",
      "7c4bbca71c80400fb11fcb76359abb18",
      "8960ec8f32804b5598099185b9d18e5a",
      "c84fd3eb1a1b46a7b3560c774beb9b91",
      "ed9c10dafea94150b4b894e106872d39",
      "7089bd8a7e274fbd9b5d0694a664ec6e",
      "ba2dc8b3458e4be0a52b0668b82c02bf",
      "edd8ebe88d9144bca70541b057c71282",
      "35a0db010d6b4a379ce7b1dfc6c311ec",
      "92ca561504a548c998b6ef2cc8c403b2",
      "ebd9c26455c545d5a9fe90e4f1a0fc95",
      "a36df433f638400b9f5bca7426e35257",
      "62349d18ac014b3c8cc6eeb017a6705c",
      "d9e731371a494c7b8f398a05c54eff7f",
      "e58ca0124f3c4e37a8f27e7bae40c59d",
      "545e5db4e2c44d49acad6819b5cf6a67",
      "c0cc129ef69a42dbb2c8d4eab0839573",
      "c09be230f7aa4f6c9013250313531161",
      "1ec6c855a60e48f29fb8b8938dcbd5b6",
      "7ead625bfd6d4074b2d10b8cdded760c",
      "51d90980a01d4b84af66aad76415a4a8",
      "2a045fc81154453993705da6d7c6346d",
      "cd28d81312a1423a87291f1e9c31c6e3",
      "b1ca4c798ea44c2e96aef8256c480662",
      "decb0fb4cbcf4d47bed6e2f7ee26061b",
      "a350fe06f7654b3d9739857b23f6d4c6",
      "3755bcec607945158616fbdb4241f302",
      "0ca498a093f1425eab977155d0734220",
      "f89cebe83dcb4b7ab6d00c232aae3816",
      "3c1ad60ddfc546eaaa4309fc8a6810ee",
      "ed16e7524b224ab3a87dd32a17f9997e",
      "445d6b842dd2475a8d3eb96be04546a0",
      "9a87fc910e744cbaaa42910478bb9722",
      "c01e426041a74783aa685bb20361865a",
      "b579c69f643143e38292004c1882dbe8",
      "282e3e88acbc47879f076b03893125c8",
      "0df06ef1ef1e4ca6a6ae1a37edb68d37",
      "882bf6f4f7d84ab9b6d4800a8aa6852f",
      "be6a495ca18d44138481969647c36dce",
      "4ac40687a16849ac9a25fd9c897324d7",
      "7e80b7eb60434ed89d205ad729f6453d",
      "c8923033c04a4f009b5bfc0a03c55fdd",
      "662e867038de453686e025f8f5ed0ddb",
      "bbad22dc04f442adb030bec66082332c",
      "7f9ae27cb7684716b5447f9137fc73c4",
      "709d4e1ccb3e46cc878c90935d54ba22",
      "4d670acd2b8944fe84673f6facfe6a69",
      "e1c8e5c40f1a4e75936908fbf3504882",
      "c807ffc86752495da718cba047753cb0",
      "03ce979a5dff4c1b9e26eb5fb3e50a7e",
      "e6304d17fc38450fa6d7d6dda40ac2a9",
      "2a0a4bcac288466597cc63757b89289d",
      "96fc9142c4d24f61a56ff39b9a47cb5c",
      "52fff8cb589647709fe1e8d79fd1b726",
      "e3d6dbea9b5a40a4b4cddcb4d0fc58d5",
      "8397685b9c874c14ba54bea82e9dcc18",
      "0dfaf73f7ae24e5aa068cdd10d8de9f3",
      "01a68bea7a4b400cae1d3e0b50c663b8",
      "2d42b887a8d042b0bf7c65a2fff17265",
      "d88b6520733e4da6b8e95ad1efef9291",
      "6e9a64d538ba4182aef9b7ff15089423",
      "72f4da1ee5af49e1b91b8670acd1209e",
      "96c8dd0748044a75a94aa07fd603d3e1",
      "c36e9471074d418c9547304deb447c89",
      "1d1df580a7e24003b758a2ec12633097",
      "5bb0ff69940d42a99ec62cdae7fed1e4",
      "af11488717104f6482184485d76fff2c",
      "44c4d117867d4a389bb6354ea4cf336a",
      "21a3ff16582840f298cfe7ecfb1f5332",
      "847c34f76b46496ebf2c696c9776d31b",
      "85dea04ebad74c49b3ccba40b01dd497",
      "6e2472ebba674b7098a1f94f276c9719",
      "614eaba708c54e77abb5f412efb532ba",
      "23b93e4372434516911610bcbaa9aa63",
      "a6a45084e9e3415b906f430c57791848",
      "d1d15f6b128743bfa239293d61388114",
      "950a0bb51ad349f099a4973fb2826725",
      "7e8ce6741eb146f08b16d0f6b7adf717",
      "d203e491e3a14e4da6af6180d8c390a4",
      "ace2099a38d34050be2dcf82252649ea",
      "a1d009ebb6794d50ad20fb4f8982dbbe",
      "d11b0020813c495e86b8af8b81abfd8d",
      "8405577c4df2472fa7ac04d82a2bdb5f",
      "49ffe1d7d56844bdb2851d3cafd17fa3",
      "3b1618fab72b441299ab0b138b90130e",
      "f9feeb9affd44357891b4f3163d808e9",
      "3e710ab1b63c49808b14bc1ff67a539f",
      "5570eeb70a6949c7b5ef9f9abe4af827",
      "b8fe114e8bcb43baa9ead1c581b89b20",
      "c59b307fde584147ac43761cfd49bae3",
      "f0f43d9823244740b23f181e8cc32c4a",
      "b01d0a0c456441089d75e9662d17e9c7",
      "77a7d89fe7bf47ba9a35011548090dd6",
      "052626c71abf4904a8f20af4db94ba3c",
      "189ac8691b5e483ba716f32aa43425a7",
      "958f0801939548b9a8756a6f4115cc24",
      "448b1d7a2a3a4c3cb7bdad1be1591170",
      "d1c02156826340888cd68440297cef10",
      "1b02006a961e450398f59e4be21c94ab",
      "6e574c99224540c89ae9c75b7a95c4e2",
      "62a9531c6d3b4231a9b565054f9777a1",
      "264090f2e8ee46e4805d56b0a8025db2",
      "c5d16ad00a9c4047b87ff600d2924c3a",
      "92ee721a44414e6ea1084349d44b73ba",
      "491f0f13a79e443c806b8399f8285dcc",
      "2ed656eeaaf14783b5b96afa41840ad2",
      "61a69fe0b9bf4d0ba9b4ca287b67e0ae",
      "83ed87acc59a4a2ab6e7fd1e1de68dcc",
      "9b3234fe5a42487c858d0473b190aabf",
      "401cab2534f14b2693ec9d61b3d51897",
      "69a16600ba924accb50558946d8bfec0",
      "205ba37728bc4422bcfdf4ab523d408b",
      "fda7c36a97794527af382a56960eb0a9",
      "0eb6d365b2ef41a3801446af8f5d2d2a",
      "e9112e6fd6a54182af544c5d141e4e79",
      "028ce3978a2249b99d3f973746231308",
      "5327a012e9ff4c6cbb000ee68e1f5e8e",
      "bf119007bc2e4f829e31d2aac7e91555",
      "5d2b936a72f2467084691e93905324f3",
      "2a4e586e5c2b4499860945e55a5aed27",
      "de1a103eafdb44ae8af2b3bd2017f8de",
      "aa1d9ccfe3d2408999767fc341b38ba1"
     ]
    },
    "id": "GwOGPejqeFra",
    "outputId": "f9b10dd9-908b-4c68-bc5f-71e56f44aa4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Searching for PDFs in: c:\\Users\\Sanjay\\Desktop\\SRM VDP HACKATHON\\Docs\n",
      "Found 9 PDFs:\n",
      "  - 4877+Life.pdf\n",
      "  - AI_and_India_Justice_CambridgeUPress (1).pdf\n",
      "  - AI_and_India_Justice_CambridgeUPress.pdf\n",
      "  - Responsible-AI-22022021.pdf\n",
      "  - V5I564.pdf\n",
      "  - legal 2.pdf\n",
      "  - legal 3.pdf\n",
      "  - legal 4.pdf\n",
      "  - legal1.pdf\n",
      "Extracted 36425 chars from 4877+Life.pdf\n",
      "Extracted 36525 chars from AI_and_India_Justice_CambridgeUPress (1).pdf\n",
      "Extracted 36525 chars from AI_and_India_Justice_CambridgeUPress.pdf\n",
      "Extracted 93016 chars from Responsible-AI-22022021.pdf\n",
      "Extracted 33153 chars from V5I564.pdf\n",
      "Extracted 0 chars from legal 2.pdf\n",
      "Extracted 12212 chars from legal 3.pdf\n",
      "Extracted 0 chars from legal 4.pdf\n",
      "Extracted 9823 chars from legal1.pdf\n",
      "Total chunks: 401\n",
      "Loading embedder: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95720c352f0b4010a2897ae3ba7229db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3909f10f7bc4e948ccc5b55234aca59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b247e6174234aff98bf27b57c3c8379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c67c214e4f45ea8360da82f9764b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d68650587e64084a025faf2fcd49416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94274a4aad546549775fcdf9d0aa867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4b898e703041cebf30905d640093e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (401, 384)\n",
      "FAISS index size: 401\n",
      "Saved faiss.index and rag_metas.pkl\n",
      "Loading generator: google/flan-t5-small device: -1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LEGAL AI SYSTEM READY!\n",
      "======================================================================\n",
      "System loaded with:\n",
      "   - 9 legal documents\n",
      "   - 401 text chunks indexed\n",
      "   - 401 embeddings created\n",
      "======================================================================\n",
      "\n",
      "You can now run the query cells below to test the system!\n"
     ]
    }
   ],
   "source": [
    "# LOCAL WINDOWS VERSION - Legal AI RAG System\n",
    "\n",
    "# 0) Installs (run once)\n",
    "%pip install -q sentence-transformers faiss-cpu transformers PyPDF2\n",
    "\n",
    "# 1) Imports\n",
    "import os, glob, io, pickle\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# 2) Detect PDFs - ADAPTED FOR WINDOWS\n",
    "# Get the current directory and look in the Docs folder\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__)) if '__file__' in globals() else os.getcwd()\n",
    "docs_folder = os.path.join(current_dir, \"Docs\")\n",
    "\n",
    "# Fallback: if running in notebook, use the notebook's directory\n",
    "if not os.path.exists(docs_folder):\n",
    "    docs_folder = r\"c:\\Users\\Sanjay\\Desktop\\SRM VDP HACKATHON\\Docs\"\n",
    "\n",
    "print(f\"Searching for PDFs in: {docs_folder}\")\n",
    "\n",
    "pdf_paths = []\n",
    "if os.path.exists(docs_folder):\n",
    "    for ext in (\"*.pdf\", \"*.PDF\"):\n",
    "        pdf_paths += glob.glob(os.path.join(docs_folder, ext))\n",
    "pdf_paths = sorted(set(pdf_paths))\n",
    "\n",
    "print(f\"Found {len(pdf_paths)} PDFs:\")\n",
    "for p in pdf_paths:\n",
    "    print(f\"  - {os.path.basename(p)}\")\n",
    "\n",
    "if not pdf_paths:\n",
    "    raise SystemExit(f\"No PDFs found in {docs_folder}. Please check the path.\")\n",
    "\n",
    "# 3) Extract text from PDFs\n",
    "def extract_pdf_text(path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        reader = PdfReader(path)\n",
    "        for p in reader.pages:\n",
    "            page_text = p.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {path}: {e}\")\n",
    "    return text\n",
    "\n",
    "raw_texts = {}\n",
    "for p in pdf_paths:\n",
    "    txt = extract_pdf_text(p)\n",
    "    raw_texts[p] = txt\n",
    "    print(f\"Extracted {len(txt)} chars from {os.path.basename(p)}\")\n",
    "\n",
    "# 4) Chunking with overlap - REDUCED CHUNK SIZE for better model performance\n",
    "def chunk_text(text, chunk_size=800, overlap=150):\n",
    "    chunks = []\n",
    "    if not text:\n",
    "        return chunks\n",
    "    start = 0\n",
    "    L = len(text)\n",
    "    while start < L:\n",
    "        end = min(L, start + chunk_size)\n",
    "        chunk = text[start:end].strip()\n",
    "        if chunk:\n",
    "            chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "docs = []\n",
    "metas = []\n",
    "for path, txt in raw_texts.items():\n",
    "    cks = chunk_text(txt, chunk_size=800, overlap=150)\n",
    "    for i, c in enumerate(cks):\n",
    "        docs.append(c)\n",
    "        metas.append({\"source\": os.path.basename(path), \"chunk_id\": i})\n",
    "print(f\"Total chunks: {len(docs)}\")\n",
    "\n",
    "# 5) Create embeddings (batch)\n",
    "embed_model_name = \"all-MiniLM-L6-v2\"\n",
    "print(\"Loading embedder:\", embed_model_name)\n",
    "embedder = SentenceTransformer(embed_model_name)\n",
    "\n",
    "batch_size = 64\n",
    "emb_list = []\n",
    "for i in range(0, len(docs), batch_size):\n",
    "    batch = docs[i:i+batch_size]\n",
    "    e = embedder.encode(batch, show_progress_bar=True, convert_to_numpy=True)\n",
    "    emb_list.append(e)\n",
    "embeddings = np.vstack(emb_list).astype(\"float32\")\n",
    "print(\"Embeddings shape:\", embeddings.shape)\n",
    "\n",
    "# 6) Build FAISS index and persist\n",
    "d = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeddings)\n",
    "print(\"FAISS index size:\", index.ntotal)\n",
    "\n",
    "faiss.write_index(index, \"faiss.index\")\n",
    "with open(\"rag_metas.pkl\",\"wb\") as f:\n",
    "    pickle.dump({\"metas\": metas, \"docs\": docs}, f)\n",
    "print(\"Saved faiss.index and rag_metas.pkl\")\n",
    "\n",
    "# 7) Generator model (small, CPU-friendly by default)\n",
    "gen_model_name = \"google/flan-t5-small\"\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(\"Loading generator:\", gen_model_name, \"device:\", device)\n",
    "generator = pipeline(\"text2text-generation\", model=gen_model_name, device=device, max_length=512)\n",
    "\n",
    "# 8) Retriever + RAG answer function\n",
    "def retrieve_topk(query, top_k=4):\n",
    "    q_emb = embedder.encode([query]).astype(\"float32\")\n",
    "    D, I = index.search(q_emb, top_k)\n",
    "    results = []\n",
    "    for idx in I[0]:\n",
    "        results.append({\"chunk\": docs[idx], \"meta\": metas[idx]})\n",
    "    return results\n",
    "\n",
    "def build_context(retrieved, max_chars=1500):\n",
    "    \"\"\"Build context with character limit to avoid token overflow\"\"\"\n",
    "    parts = []\n",
    "    total_chars = 0\n",
    "    for i, r in enumerate(retrieved):\n",
    "        chunk_text = r['chunk']\n",
    "        # Truncate if adding this chunk would exceed limit\n",
    "        if total_chars + len(chunk_text) > max_chars:\n",
    "            remaining = max_chars - total_chars\n",
    "            if remaining > 100:  # Only add if meaningful text remains\n",
    "                chunk_text = chunk_text[:remaining] + \"...\"\n",
    "                parts.append(f\"Source: {r['meta']['source']} (chunk {r['meta']['chunk_id']})\\n{chunk_text}\")\n",
    "            break\n",
    "        parts.append(f\"Source: {r['meta']['source']} (chunk {r['meta']['chunk_id']})\\n{chunk_text}\")\n",
    "        total_chars += len(chunk_text)\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def answer_query(query, top_k=3):\n",
    "    \"\"\"Reduced top_k to 3 for better performance\"\"\"\n",
    "    retrieved = retrieve_topk(query, top_k=top_k)\n",
    "    context = build_context(retrieved, max_chars=1500)\n",
    "    prompt = (\n",
    "        \"Answer the question using the context below. Be concise.\\n\\n\"\n",
    "        f\"CONTEXT:\\n{context}\\n\\nQUESTION: {query}\\n\\nANSWER:\"\n",
    "    )\n",
    "    out = generator(prompt, max_new_tokens=200, do_sample=False)[0][\"generated_text\"].strip()\n",
    "    # sometimes models echo the prompt; try to strip if echoed\n",
    "    if out.startswith(prompt):\n",
    "        out = out[len(prompt):].strip()\n",
    "    chat_history.append((query, out))\n",
    "    return out, retrieved\n",
    "\n",
    "# 9) System ready notification\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"LEGAL AI SYSTEM READY!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"System loaded with:\")\n",
    "print(f\"   - {len(pdf_paths)} legal documents\")\n",
    "print(f\"   - {len(docs)} text chunks indexed\")\n",
    "print(f\"   - {embeddings.shape[0]} embeddings created\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nYou can now run the query cells below to test the system!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Y9RyeRrwfJV6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced legal query function loaded!\n",
      "Configured for detailed legal analysis with improved formatting.\n"
     ]
    }
   ],
   "source": [
    "# LEGAL & JUSTICE OPTIMIZED RAG ANSWER FUNCTION\n",
    "# IMPORTANT: Make sure to run cell 3 (Main RAG System) before running this cell!\n",
    "\n",
    "def format_legal_answer(text):\n",
    "    \"\"\"\n",
    "    Formats the answer with proper line breaks and structure for better readability.\n",
    "    \"\"\"\n",
    "    # Clean up the text\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Add paragraph breaks for readability\n",
    "    import re\n",
    "    # Split into sentences and group them\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    \n",
    "    # Group sentences into paragraphs (every 3-4 sentences)\n",
    "    paragraphs = []\n",
    "    current_para = []\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        current_para.append(sentence)\n",
    "        if (i + 1) % 3 == 0 or i == len(sentences) - 1:\n",
    "            paragraphs.append(' '.join(current_para))\n",
    "            current_para = []\n",
    "    \n",
    "    return '\\n\\n'.join(paragraphs)\n",
    "\n",
    "def build_context_optimized(retrieved, max_chars=1800):\n",
    "    \"\"\"Build context with character limit to avoid token overflow\"\"\"\n",
    "    parts = []\n",
    "    total_chars = 0\n",
    "    for i, r in enumerate(retrieved):\n",
    "        chunk_text = r['chunk']\n",
    "        # Truncate if adding this chunk would exceed limit\n",
    "        if total_chars + len(chunk_text) > max_chars:\n",
    "            remaining = max_chars - total_chars\n",
    "            if remaining > 150:  # Only add if meaningful text remains\n",
    "                chunk_text = chunk_text[:remaining] + \"...\"\n",
    "                parts.append(chunk_text)\n",
    "            break\n",
    "        parts.append(chunk_text)\n",
    "        total_chars += len(chunk_text)\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "def answer_query(query, top_k=4):\n",
    "    \"\"\"\n",
    "    Retrieves top_k chunks related to a legal query and generates\n",
    "    a detailed, factual, law-oriented answer.\n",
    "    Optimized to avoid token length issues.\n",
    "    \n",
    "    NOTE: This overrides the basic answer_query() function from cell 3\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve relevant chunks\n",
    "    retrieved = retrieve_topk(query, top_k=top_k)\n",
    "    context = build_context_optimized(retrieved, max_chars=1800)\n",
    "\n",
    "    # Improved prompt for detailed legal analysis\n",
    "    legal_prompt = f\"\"\"You are a legal research assistant. Based on the legal text provided, give a comprehensive answer to the question. Include relevant details, principles, and implications.\n",
    "\n",
    "LEGAL TEXT:\n",
    "{context}\n",
    "\n",
    "QUESTION: {query}\n",
    "\n",
    "Provide a detailed answer (at least 3-4 sentences):\"\"\"\n",
    "\n",
    "    # Generate the answer with more tokens for detailed response\n",
    "    out = generator(legal_prompt, max_new_tokens=300, do_sample=False, truncation=True)[0]['generated_text'].strip()\n",
    "\n",
    "    # Extract just the answer\n",
    "    if \"Provide a detailed answer\" in out:\n",
    "        parts = out.split(\"Provide a detailed answer\")\n",
    "        if len(parts) > 1:\n",
    "            out = parts[-1].strip()\n",
    "            # Remove the instruction suffix\n",
    "            out = out.replace(\"(at least 3-4 sentences):\", \"\").strip()\n",
    "            out = out.lstrip(':').strip()\n",
    "    \n",
    "    # Format the answer for better readability\n",
    "    formatted_answer = format_legal_answer(out)\n",
    "\n",
    "    # Save in chat history\n",
    "    chat_history.append((query, formatted_answer))\n",
    "\n",
    "    return formatted_answer, retrieved\n",
    "\n",
    "print(\"Enhanced legal query function loaded!\")\n",
    "print(\"Configured for detailed legal analysis with improved formatting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4deilg0gsaJ",
    "outputId": "4aadd984-dcb4-4c6b-d849-ec10da205eaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Legal Query with Structured Output\n",
      "\n",
      "================================================================================\n",
      "\n",
      "LEGAL ANALYSIS:\n",
      "================================================================================\n",
      "The main legal principle discussed in the document is rimination on the basis of religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. The Constitution prohibits discrimination based on certain markers, it also provides for positive discrimination in the form of affirmative action. Article 15: rimination on the basis of religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc.\n",
      "\n",
      "The Constitution prohibits discrimination based on certain markers, it also provides for positive discrimination in the form of affirmative action. Article 15: rimination on the basis of religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. The Constitution prohibits discrimination based on certain markers, it also provides for positive discrimination in the form of affirmative action.\n",
      "\n",
      "Article 15: rimination on the basis of religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. The Constitution guarantees accountability of all State action to individuals and groups. Box 13: Creation of Principles\n",
      "\n",
      "================================================================================\n",
      "\n",
      "SOURCES CONSULTED:\n",
      "  1. Responsible-AI-22022021.pdf (chunk 106)\n",
      "  2. Responsible-AI-22022021.pdf (chunk 108)\n",
      "  3. legal 3.pdf (chunk 16)\n",
      "  4. V5I564.pdf (chunk 39)\n",
      "\n",
      "LEGAL ANALYSIS:\n",
      "================================================================================\n",
      "The main legal principle discussed in the document is rimination on the basis of religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. The Constitution prohibits discrimination based on certain markers, it also provides for positive discrimination in the form of affirmative action. Article 15: rimination on the basis of religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc.\n",
      "\n",
      "The Constitution prohibits discrimination based on certain markers, it also provides for positive discrimination in the form of affirmative action. Article 15: rimination on the basis of religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. The Constitution prohibits discrimination based on certain markers, it also provides for positive discrimination in the form of affirmative action.\n",
      "\n",
      "Article 15: rimination on the basis of religion, race, caste, sex, descent, place of birth or residence in matters of education, employment, access to public spaces, etc. The Constitution guarantees accountability of all State action to individuals and groups. Box 13: Creation of Principles\n",
      "\n",
      "================================================================================\n",
      "\n",
      "SOURCES CONSULTED:\n",
      "  1. Responsible-AI-22022021.pdf (chunk 106)\n",
      "  2. Responsible-AI-22022021.pdf (chunk 108)\n",
      "  3. legal 3.pdf (chunk 16)\n",
      "  4. V5I564.pdf (chunk 39)\n"
     ]
    }
   ],
   "source": [
    "# Test the Enhanced Legal Query System\n",
    "print(\"Testing Legal Query with Structured Output\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ans, ret = answer_query(\"Explain the main legal principle discussed in the document.\", top_k=4)\n",
    "\n",
    "print(\"\\nLEGAL ANALYSIS:\")\n",
    "print(\"=\" * 80)\n",
    "print(ans)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"\\nSOURCES CONSULTED:\")\n",
    "for i, r in enumerate(ret, 1):\n",
    "    print(f\"  {i}. {r['meta']['source']} (chunk {r['meta']['chunk_id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Interactive Legal Queries\n",
    "Run the cells below to test different legal questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LEGAL QUERY TEST #1\n",
      "================================================================================\n",
      "\n",
      "Question: What are the main legal challenges discussed regarding AI and justice?\n",
      "\n",
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "Privacy and data protection, security v tion to deal with this aspect of AI remains with the High C ourts of respective state and the Supreme Court of India.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources Referenced:\n",
      "  1. 4877+Life.pdf (chunk 11)\n",
      "  2. 4877+Life.pdf (chunk 8)\n",
      "  3. 4877+Life.pdf (chunk 23)\n",
      "  4. legal1.pdf (chunk 13)\n",
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "Privacy and data protection, security v tion to deal with this aspect of AI remains with the High C ourts of respective state and the Supreme Court of India.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources Referenced:\n",
      "  1. 4877+Life.pdf (chunk 11)\n",
      "  2. 4877+Life.pdf (chunk 8)\n",
      "  3. 4877+Life.pdf (chunk 23)\n",
      "  4. legal1.pdf (chunk 13)\n"
     ]
    }
   ],
   "source": [
    "# Test Query 1: General Legal Overview\n",
    "print(\"\\nLEGAL QUERY TEST #1\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query1 = \"What are the main legal challenges discussed regarding AI and justice?\"\n",
    "print(f\"\\nQuestion: {query1}\\n\")\n",
    "\n",
    "ans, sources = answer_query(query1, top_k=4)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(\"-\" * 80)\n",
    "print(ans)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nSources Referenced:\")\n",
    "for i, s in enumerate(sources, 1):\n",
    "    print(f\"  {i}. {s['meta']['source']} (chunk {s['meta']['chunk_id']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LEGAL QUERY TEST #2\n",
      "================================================================================\n",
      "\n",
      "Question: What are the implications of AI in judicial decision making?\n",
      "\n",
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "Artificial Intelligence in the Indian Criminal Justice System: Advancements, Challenges, and Ethical Implications\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources Referenced:\n",
      "  1. 4877+Life.pdf (chunk 48)\n",
      "  2. 4877+Life.pdf (chunk 8)\n",
      "  3. Responsible-AI-22022021.pdf (chunk 84)\n",
      "  4. legal1.pdf (chunk 9)\n",
      "Answer:\n",
      "--------------------------------------------------------------------------------\n",
      "Artificial Intelligence in the Indian Criminal Justice System: Advancements, Challenges, and Ethical Implications\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Sources Referenced:\n",
      "  1. 4877+Life.pdf (chunk 48)\n",
      "  2. 4877+Life.pdf (chunk 8)\n",
      "  3. Responsible-AI-22022021.pdf (chunk 84)\n",
      "  4. legal1.pdf (chunk 9)\n"
     ]
    }
   ],
   "source": [
    "# Test Query 2: Specific Legal Topic\n",
    "print(\"\\nLEGAL QUERY TEST #2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query2 = \"What are the implications of AI in judicial decision making?\"\n",
    "print(f\"\\nQuestion: {query2}\\n\")\n",
    "\n",
    "ans, sources = answer_query(query2, top_k=4)\n",
    "\n",
    "print(\"Answer:\")\n",
    "print(\"-\" * 80)\n",
    "print(ans)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nSources Referenced:\")\n",
    "for i, s in enumerate(sources, 1):\n",
    "    print(f\"  {i}. {s['meta']['source']} (chunk {s['meta']['chunk_id']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CUSTOM LEGAL QUERY\n",
      "==========================================================================================\n",
      "\n",
      "Question: What are the ethical considerations for AI in the legal system?\n",
      "\n",
      "Legal Analysis:\n",
      "------------------------------------------------------------------------------------------\n",
      "Ethical impact assessments (EIA) for AI systems before deployment\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Retrieved from these sources:\n",
      "  1. V5I564.pdf - Chunk 43 (800 chars)\n",
      "  2. 4877+Life.pdf - Chunk 11 (800 chars)\n",
      "  3. 4877+Life.pdf - Chunk 45 (800 chars)\n",
      "\n",
      "==========================================================================================\n",
      "Legal Analysis:\n",
      "------------------------------------------------------------------------------------------\n",
      "Ethical impact assessments (EIA) for AI systems before deployment\n",
      "------------------------------------------------------------------------------------------\n",
      "\n",
      "Retrieved from these sources:\n",
      "  1. V5I564.pdf - Chunk 43 (800 chars)\n",
      "  2. 4877+Life.pdf - Chunk 11 (800 chars)\n",
      "  3. 4877+Life.pdf - Chunk 45 (800 chars)\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Custom Query - Ask Your Own Question!\n",
    "# Change the question below to test different legal queries\n",
    "\n",
    "print(\"\\nCUSTOM LEGAL QUERY\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "my_question = \"What are the ethical considerations for AI in the legal system?\"\n",
    "\n",
    "print(f\"\\nQuestion: {my_question}\\n\")\n",
    "\n",
    "ans, sources = answer_query(my_question, top_k=4)\n",
    "\n",
    "print(\"Legal Analysis:\")\n",
    "print(\"-\" * 90)\n",
    "print(ans)\n",
    "print(\"-\" * 90)\n",
    "\n",
    "print(\"\\nRetrieved from these sources:\")\n",
    "for i, s in enumerate(sources, 1):\n",
    "    print(f\"  {i}. {s['meta']['source']} - Chunk {s['meta']['chunk_id']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}